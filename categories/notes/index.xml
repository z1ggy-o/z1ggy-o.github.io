<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Notes on Gy's Blog</title><link>https://z1ggy-o.github.io/categories/notes/</link><description>Recent content in Notes on Gy's Blog</description><generator>Hugo -- 0.140.1</generator><language>en-us</language><lastBuildDate>Sat, 28 Dec 2024 18:26:22 +0800</lastBuildDate><atom:link href="https://z1ggy-o.github.io/categories/notes/index.xml" rel="self" type="application/rss+xml"/><item><title>FAST'20 - BCW: Buffer-Controlled Writes to HDDs for SSD-HDD Hybrid Storage Server</title><link>https://z1ggy-o.github.io/papers/wang-2020-bcw/</link><pubDate>Sun, 17 Sep 2023 12:51:01 +0000</pubDate><guid>https://z1ggy-o.github.io/papers/wang-2020-bcw/</guid><description>&lt;h2 id="short-summary">Short Summary&lt;/h2>
&lt;p>HDDs are under utilized in hybrid cloud storage systems which makes SSD to handle most of
the requests.
This shorts the life of SSDs and also wants the utilization of HDDs.&lt;/p>
&lt;p>The authors of this paper find that the write requests can have $Î¼$s-level latency when
using HDD if the buffer in HDD is not full.
They leverage this finding to let HDD to handle write requests if the requests can fit into
the in disk buffer.&lt;/p></description></item><item><title>SOSP'19 - File Systems Unift as Distributed Storage Backends: Lessons from 10 Years of Ceph Evolution</title><link>https://z1ggy-o.github.io/papers/1.aghayev-2019-filesystemunfit/</link><pubDate>Sun, 17 Jan 2021 00:29:00 +0900</pubDate><guid>https://z1ggy-o.github.io/papers/1.aghayev-2019-filesystemunfit/</guid><description>&lt;h2 id="short-summary">Short Summary&lt;/h2>
&lt;p>This paper mostly consists of two parts. The first part tells us why the &lt;code>FileStore&lt;/code> has performance issues.
And the second part tells us how Ceph team build &lt;code>BlueStore&lt;/code> based on the
lessons that they learnt from &lt;code>FileStore&lt;/code>.&lt;/p>
&lt;p>The main ideas of &lt;code>BlueStore&lt;/code> are:&lt;/p>
&lt;ol>
&lt;li>Avoid using local file system to store and represent Ceph objects&lt;/li>
&lt;li>Use KV-store to provide transaction mechanism instead of build it by ourself&lt;/li>
&lt;/ol>
&lt;h2 id="what-s-the-problem">What&amp;rsquo;s the problem&lt;/h2>
&lt;p>There is a software called &lt;code>storage backend&lt;/code> in Ceph. The &lt;code>storage backend&lt;/code> is
responsible to accept requests from upper layer of Ceph and do the real I/O on
storage devices.&lt;/p></description></item><item><title>FAST'20 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine</title><link>https://z1ggy-o.github.io/papers/he-2020-readasneeded/</link><pubDate>Sat, 26 Dec 2020 20:15:00 +0900</pubDate><guid>https://z1ggy-o.github.io/papers/he-2020-readasneeded/</guid><description>&lt;h2 id="short-summary">Short Summary&lt;/h2>
&lt;p>This paper proposed a NAND-flash SSD-friendly full text engine. This engine can
achieve better performance than existing engines with much less memory requested.&lt;/p>
&lt;p>They reduce the unnecessary I/O (both the number of I/O and the volume). The
engine does not cache data into memory, instead, read data every time when query
arrive.&lt;/p>
&lt;p>They also tried to increase the request size to exploit SSD internal parallelism.&lt;/p>
&lt;h2 id="what-is-the-problem">What Is the Problem&lt;/h2>
&lt;p>Search engines pose great challenges to storage systems:&lt;/p></description></item></channel></rss>