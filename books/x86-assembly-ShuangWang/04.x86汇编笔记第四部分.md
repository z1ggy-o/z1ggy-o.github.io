---
title: Note - x86 汇编语言（4）：分页机制
categories: 
  - articles
tags: 
  - Computer Organization
toc: true
isCJKLanguage: true
date: 2022-07-10 08:39:25
draft: false
permalink: /pages/547566/
author: Me
---

---

到了该系列笔记的最后一个章节了。之前的几个章节中，我们讨论了最直白的 8086 分段访问模型，又讲到了保护模式下的分段访问模式，现在我们来讲一讲实际生活中的默认内存管理方式--分页。

本文中我们只谈寻址部分的内容，关于分页所提供的保护机能不作涉及。

其余章节如下：
- [第一部分: 计算机基础和实模式](../01.x86汇编笔记第一部分/)
- [第二部分：保护模式下的分段寻址和权限](02.x86汇编笔记第二部分/)
- [第三部分：多任务支持](03.x86汇编笔记第三部分/)
- [第四部分：分页机制](04.x86汇编笔记第四部分/)

## 为什么分页？

聊到分页，我们经常将其和虚拟内存联系在一起。而虚拟内存又是多任务的好帮手。但是虚拟内存的实现并不需要分页。分页是为了更高效的进行内存管理。

在多任务的系统中，我们之前已经通过 LDT 隔离了各个任务的内存空间。而段描述符中的 `P` 位标志着该段是否存在于内存中，使得我们可以利用它将一个段交换到二级存储器中，为内存腾出空间。这似乎和广泛了解的分页虚拟内存没什么区别，但实际上有两个显著的问题：
1. 段是不定长的。操作系统想要在内存里找一个合适的位置不容易。会出现“外部碎片化”的问题，即，有些内存空闲空间因为太小，不能被使用而浪费。
2. 段只能以整体进行交换。因为只有段描述符有一个 `P` 位，我们只能选择将整个段换出，或导入。如果想要载入一个大段，可能要换出多个现有的段。

综上两个原因，基于段的内存管理模式较为复杂，效率也较低。还有，一个段的大小不能大于物理内存的空间，否则无法被载入。

分页机制则是以固定的大小对内存进行分割，每个单位就是所谓的“页”。对于每个页，我们都有相应的数据结构对其进行描述和管理。

对固定大小的页进行管理有两个好处：
1. 我们的管理模式变得更加简单。定长总是比不定长好处理。
2. 因为一般页的单位较小（例如 4KB）我们能够对内存进行更细颗粒度的管理，也突破了段大于物理内存则无法被载入运行的限制。

使用分页机制也会有碎片化的问题，相对的，是“内部碎片化”，即一个页没有被完全使用。不过因为页的单位大小一般不大，相对外部碎片化来说，内部碎片化带来的内存浪费要少许多。

## 分页机制的工作原理

在 Intel 的设计中，分页机制是基于分段机制之上的。无论是否使用分页，分段机制都必须被开启。其结果就是，我们之前提到的寻址和保护机制等在分页模型下继续存在，我们是在之前的基础上追加分页。即，将段分成更小的页。

在之前的分段模型中，不论是实模式还是保护模式下，都是基于“段基地址 + 段内偏移”的方式获得的。处理器中有专门对其进行计算的模块，我们叫它*段部件*。我们把由段部件获得的地址称为*线性地址*。

在不开启分页机制时，线性地址就是内存物理地址。它被直接用到地址线上，帮助我们进行寻址。在使用分页机制之后，段被进一步拆分为更小的页。操作系统按照页为单位进行内存的分配和回收。其结果就是，一个段在逻辑上是连续的，但是，被分割为多个页之后，各个页可能被分配在不同的位置。这使得段和页之间有了一层映射关系。

因为段的分割，以及其对应页的随机位置分配，之前由段部件提供的线性地址不再能被直接使用于内存寻址，而是要经过*页部件*的处理，才能得到最终可用的内存物理地址。所以，在开启分页之后，段部件生成的线性地址，又被叫做*虚拟地址*。

图示大致如下：
<img src="https://raw.githubusercontent.com/z1ggy-o/static_resources/main/img/virtualMem2phyMem.png" width="400"/>

## 如何通过分页机制进行寻址

上面我们提到，在使用分页后，之前我们熟悉的线性地址不能再被直接使用，而是需要再被进行一次转换。

这个转换倒也不复杂。假设我们有一个段，它被分成了 3 个页。因为页的大小是固定的，我们可以根据具体的线性地址，通过计算，知道对应的页是谁。基于那个页的基地址，再加上偏移量，我们就从线性地址转换到了内存的物理地址。

从上面的过程可以发现，要把通过分段获得的线性地址（虚拟地址）转换为分页后的物理地址，我们需要两个信息：
1. 段和页的映射信息。
2. 一个页的相关信息。最基本的，这个页具体的物理地址。

具体的，我们把内存空间按页的大小进行分割之后，使用*页表*来存放各个页的相关信息。因为页的大小固定，通过简单的除法就能从线性地址得知页在页表中的 index；而对应的*页表项*中存放了该页的信息。

<img src="https://raw.githubusercontent.com/z1ggy-o/static_resources/main/img/pageTable.png" width="400"/>

### 页表分级

上面其实已经体现了分页的工作核心。但是，实际应用起来，我们会发现一个问题，就是页表太大了。

以 32 位系统为例。系统的寻址空间是 4GB，每个页表项大小为 4 bytes (32 位地址），假设以最常见的 4KB 为一个页的大小，则页表需要占用 4MB 的空间。

这个空间占用看似不大，但是，接下来我们会提到，为了加强任务间的隔离，各个任务会使用自己的一份页表。这样一来，当同时运行的任务数量变多时，光页表自己就已然成为了内存消耗大户。

为了解决这个问题，人们选择使用页表分级的方式来节约内存。以二级表为例，除了上述的页表之外，再添加一个*页目录表*。我们把页表里的表项分组，将上述的一个大的页表，分成多个小的页表。然后，页目录表中的表项记录页表们的信息。如此一来，对应页所在的页表就可以在需要的时候才创建，在不被使用的时候被交换到二级存储器中去，节约内存空间。

有些朋友可能会问，只用一层级的页表，我们按需扩容不行吗？没用到的内存地址，就不为它生成对应的页表区域，需要的时候再扩展，那不也行吗？可惜的是，我们的线性地址和页表项的映射关系计算是静态的，如果一开始就需要用到高位的内存空间，又只有一级页表，那页表必须一开始就覆盖整个地址空间。碰巧的是，我们还真的需要在一开始就使用到高位和低位的地址空间，所以答案是否定的。为什么会用到，卖个关子，稍后再说。

页目录表，页表，以及对应内存的关系大致如下图所示：
![](https://raw.githubusercontent.com/z1ggy-o/static_resources/main/img/pageTableLevels.png)

页目录表以及页表各自的表项内容如下。除了基地址外，还有一些域，它们和页的使用情况记录有关。感兴趣的朋友可以另外查询手册了解。
![](https://raw.githubusercontent.com/z1ggy-o/static_resources/main/img/pageTableEntry.png)

### 地址变换过程

有了地址变换所需的数据结构，现在我们就来看一看具体的地址变换过程。我们假设一个页的大小是 4KB，页表的页表项为 4 bytes，页目录的表项也为 4 bytes，每 1024 个页表项被分为一组，登记在页目录中。因为映射方式是静态的，过程其实很直接：
1. 页部件将段部件给出的线性地址分为三段：高 10 位，中 10 位，低 12 位。
2. 高 10 位作为页目录表的 index，帮助我们找到对应页表区段的起始地址。
3. 中 10 位作为页表的 index，帮我们从页表中找到对应页的页表项。
4. 页表项中有着该页的基地址，线性地址的低 12 位作为页内偏移量，和基地址相加，最终获得物理地址。

看图理解会来得更直接一些。
![](https://raw.githubusercontent.com/z1ggy-o/static_resources/main/img/LAtoPA.png)

## 分页以及虚拟地址空间

文章开头我们提到，保护模式下的分段机制已经可以支持虚拟内存。不过，在分段机制下，所有的任务共享者一个地址空间。虽然每个任务有自己的 LDT，但是各个 LDT 中的段描述符内的地址肯定是不同的，除非我们故意要指向相同的区域。

在分页机制下，因为通过页表，我们引入了另一层的间接寻址访问。基于这个间接访问层，我们可以通过使用不同页表的方式，创建多个虚拟内存空间。这也是处理器设计者推荐的，所以之前我们说，一般我们会为每个任务创建它自己的页表。

通过使用不同的页表，就算两个任务使用相同的虚拟地址进行寻址，因为页表内最终的映射的位置不同，它们会访问到不同的内存地址。这提供了更好的任务间隔离。

### 硬件支持

有多个页表，就自然有了去哪找到页表的问题。和之前 LDT 相似，处理器为记录页表的基地址，提供了一个单独的寄存器，这个寄存器就是 CR3。它存放着当前任务的第一级页表（在我们的例子中，页目录表）的起始物理地址。每个任务的 TSS 中也有相应的域记录第一级页表的起始地址，所以任务切换的时候，处理器会自动的帮我们进行切换页表。

### 全局空间和局部空间的映射

每个任务有了自己的页表，这使得每个任务都访问自己的私有页面。但是除了各个用户任务私有的内容之外，它们还要访问一些公共资源，比如操作系统内核提供的公共函数。

在之前的分段模型中，我们通过各种门来进行内核公共函数的调用。因为分页是基于分段之上的，所以之前的内容并没有改变。但，因为现在任务完全使用自己的虚拟空间，为了让它们能够找到那些公共的资源，我们需要相应的为它们设置页表来映射到对应的位置。使得每个任务可以通过自己的虚拟空间地址和页表找到这些资源。

解决方法倒也不复杂。我们将整个虚拟内存空间分为*局部空间*和*全局空间*两个部分。全局空间的地址范围内，我们将各个任务的页表都映射到共享的资源去；对于每个任务自己的内存需求，则限制在局部空间的地址范围内。

一般来说，我们把地址空间的高地址区作为全局空间，低地址区作为局部空间。这就是之前页表分级部分中提到的，我们要同时使用高低地址区域的原因。

## 开启分页功能的小技巧

### 平坦模型

32 位以上架构中，不需要分段也可以拥有完全的寻址能力。加上分页也提供了任务间的隔离，使得分段不再具有太大的意义。

在实际实现中，人们会仅仅声明一个拥有整个空间寻址能力的段，基于这个段之上利用分页进行内存管理。这就是所谓的分段模型。如此一来，一个程序中的所有数据都按照统一的基地址来安排，省去一些切换段寄存器的麻烦。

### 解决页表的“蛋鸡问题”

敏锐的朋友可能发现了，上述的分页访问模式中，在修改页目录表的时候，有一个“鸡生蛋，蛋生鸡”的问题。它发生在访问页目录表的时候。因为开启分页后，一切的访问都需要通过页目录表，页表，以及页部件的配合，来将虚拟地址转换为物理地址。

我们可以通过 CR3 获得页目录表的物理地址，但没有用。就算它是我们想要的结果，我们现在却不能用它进行直接的寻址。想要修改页目录表，我们需要通过它自己先来找到它的物理地址。

为了解决这个问题，我们需要在开启分页前，在页目录表中添加指向自己的页表信息。一个巧妙的办法是将页目录表中一个表项指向目录表自己，如此一来，它既是页目录表，也是页表。书中给的做法是在页目录表最后的一个表项内添上目录表的物理地址，便于构造相应的虚拟地址。

## 总结

- 因为分段机制不能很好的应对多任务情况下的内存管理，我们引入了分页机制。
- Intel 的架构中，分页机制工作在分段机制之上。分页以固定长度为单位对段进行分割，并进行管理。
- 为了记录段和页之间的映射关系，我们添加了页表这样一个数据信息。相应的，为了适应多任务切换，处理中有 CR3 寄存器存储页表基地址，TSS 中也有相应的域来存储该地址。
- 分页可以提供多个虚拟空间，使得任务间的隔离更加完全。
