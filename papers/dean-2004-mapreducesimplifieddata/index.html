<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>OSDI'04 - MapReduce: simplified data processing on large clusters | Gy's Blog</title>
<meta name=keywords content="distributed-systems"><meta name=description content="MOTIVATION
Google does a lot of straightforward computations in their workload. However, since the input data is large, they need to distribute the computations in order to finish the job in a reasonable amount of time.
To parallelize the computation, to distribute the data, and to handle failures make the original simple computation code complex. Thus, we need a better way to handle these issues, so the programmer only needs to focus on the computation task itself and does not need to be a distributed systems expert."><meta name=author content="map[link:https://github.com/z1ggy-o name:gyzhu]"><link rel=canonical href=https://z1ggy-o.github.io/papers/dean-2004-mapreducesimplifieddata/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://z1ggy-o.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://z1ggy-o.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://z1ggy-o.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://z1ggy-o.github.io/apple-touch-icon.png><link rel=mask-icon href=https://z1ggy-o.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://z1ggy-o.github.io/papers/dean-2004-mapreducesimplifieddata/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://z1ggy-o.github.io/papers/dean-2004-mapreducesimplifieddata/"><meta property="og:site_name" content="Gy's Blog"><meta property="og:title" content="OSDI'04 - MapReduce: simplified data processing on large clusters"><meta property="og:description" content="MOTIVATION Google does a lot of straightforward computations in their workload. However, since the input data is large, they need to distribute the computations in order to finish the job in a reasonable amount of time.
To parallelize the computation, to distribute the data, and to handle failures make the original simple computation code complex. Thus, we need a better way to handle these issues, so the programmer only needs to focus on the computation task itself and does not need to be a distributed systems expert."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="papers"><meta property="article:published_time" content="2022-05-16T09:44:18+00:00"><meta property="article:modified_time" content="2024-12-28T14:09:27+08:00"><meta property="article:tag" content="Distributed-Systems"><meta name=twitter:card content="summary"><meta name=twitter:title content="OSDI'04 - MapReduce: simplified data processing on large clusters"><meta name=twitter:description content="MOTIVATION
Google does a lot of straightforward computations in their workload. However, since the input data is large, they need to distribute the computations in order to finish the job in a reasonable amount of time.
To parallelize the computation, to distribute the data, and to handle failures make the original simple computation code complex. Thus, we need a better way to handle these issues, so the programmer only needs to focus on the computation task itself and does not need to be a distributed systems expert."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Papers","item":"https://z1ggy-o.github.io/papers/"},{"@type":"ListItem","position":2,"name":"OSDI'04 - MapReduce: simplified data processing on large clusters","item":"https://z1ggy-o.github.io/papers/dean-2004-mapreducesimplifieddata/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"OSDI'04 - MapReduce: simplified data processing on large clusters","name":"OSDI\u002704 - MapReduce: simplified data processing on large clusters","description":"MOTIVATION Google does a lot of straightforward computations in their workload. However, since the input data is large, they need to distribute the computations in order to finish the job in a reasonable amount of time.\nTo parallelize the computation, to distribute the data, and to handle failures make the original simple computation code complex. Thus, we need a better way to handle these issues, so the programmer only needs to focus on the computation task itself and does not need to be a distributed systems expert.\n","keywords":["distributed-systems"],"articleBody":"MOTIVATION Google does a lot of straightforward computations in their workload. However, since the input data is large, they need to distribute the computations in order to finish the job in a reasonable amount of time.\nTo parallelize the computation, to distribute the data, and to handle failures make the original simple computation code complex. Thus, we need a better way to handle these issues, so the programmer only needs to focus on the computation task itself and does not need to be a distributed systems expert.\nCONTRIBUTION They implement a library that can provide a simple interface that enables automatic parallelization and distribution of large-scale computations. In addition, the library handles machine failures without interaction with programmers.\nSOLUTION Inspired by the map and reduce primitives present in functional languages, they provide a restricted programming model that parallelizes the computation automatically (the computation must be deterministic). Both Map and Reduce functions are written by the user. The input data will be partitioned into M splits, and each Map task handles one of them. The intermediate output of the Map function is divided into R pieces. The Reduce task will read the intermediate output of the Map function and generate the final output files. For a cluster of machines, we have only one master machine, and the others are worker machines. The master machine assigns tasks (Map or Reduce) to workers and tracks the state of each task. The worker machines communicate with the master when work is finished or communicate with other workers to read data to process. Fault tolerance is handled by periodical communication and re-computation when a machine fails. Because the computation is deterministic, recomputing the same task is okay. Many optimizations are applied in their implementation. Check the paper for details. EVALUATION They used a cluster that consisted of around 1800 machines. Each machine has only 4GB of memory, and two 160GB IDE disks with a gigabit Ethernet link.\nThey tasted grep and sort workloads with 10^{10} 100-byte records (around 1TB). The results are shown in the terms of data throughput with the timeline.\nMAIN FINDING OF THE PAPER It is useful to abstract a common pattern of certain computing tasks, and create an infrastructure to handle the common issues.\n","wordCount":"373","inLanguage":"en","datePublished":"2022-05-16T09:44:18Z","dateModified":"2024-12-28T14:09:27+08:00","author":{"@type":"Person","name":{"link":"https://github.com/z1ggy-o","name":"gyzhu"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://z1ggy-o.github.io/papers/dean-2004-mapreducesimplifieddata/"},"publisher":{"@type":"Organization","name":"Gy's Blog","logo":{"@type":"ImageObject","url":"https://z1ggy-o.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://z1ggy-o.github.io/ accesskey=h title="Gy's Blog (Alt + H)">Gy's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://z1ggy-o.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://z1ggy-o.github.io/weekly/ title=Logs><span>Logs</span></a></li><li><a href=https://z1ggy-o.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://z1ggy-o.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://z1ggy-o.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://z1ggy-o.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://z1ggy-o.github.io/papers/>Papers</a></div><h1 class="post-title entry-hint-parent">OSDI'04 - MapReduce: simplified data processing on large clusters</h1><div class=post-meta><span title='2022-05-16 09:44:18 +0000 UTC'>May 16, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;map[link:https://github.com/z1ggy-o name:gyzhu]</div></header><div class=post-content><h2 id=motivation>MOTIVATION<a hidden class=anchor aria-hidden=true href=#motivation>#</a></h2><p>Google does a lot of straightforward computations in their workload. However, since the input data is large, they need to distribute the computations in order to finish the job in a reasonable amount of time.</p><p>To parallelize the computation, to distribute the data, and to handle failures make the original simple computation code complex. Thus, we need a better way to handle these issues, so the programmer only needs to focus on the computation task itself and does not need to be a distributed systems expert.</p><h2 id=contribution>CONTRIBUTION<a hidden class=anchor aria-hidden=true href=#contribution>#</a></h2><p>They implement a library that can provide a simple interface that enables automatic parallelization and distribution of large-scale computations. In addition, the library handles machine failures without interaction with programmers.</p><h2 id=solution>SOLUTION<a hidden class=anchor aria-hidden=true href=#solution>#</a></h2><ul><li>Inspired by the <code>map</code> and <code>reduce</code> primitives present in functional languages, they provide a restricted programming model that parallelizes the computation automatically (the computation must be deterministic).</li><li>Both Map and Reduce functions are written by the user. The input data will be partitioned into M splits, and each Map task handles one of them. The intermediate output of the Map function is divided into R pieces. The Reduce task will read the intermediate output of the Map function and generate the final output files.</li><li>For a cluster of machines, we have only one master machine, and the others are worker machines. The master machine assigns tasks (Map or Reduce) to workers and tracks the state of each task. The worker machines communicate with the master when work is finished or communicate with other workers to read data to process.</li><li>Fault tolerance is handled by periodical communication and re-computation when a machine fails. Because the computation is deterministic, recomputing the same task is okay.</li><li>Many optimizations are applied in their implementation. Check the paper for details.</li></ul><h2 id=evaluation>EVALUATION<a hidden class=anchor aria-hidden=true href=#evaluation>#</a></h2><p>They used a cluster that consisted of around 1800 machines. Each machine has only 4GB of memory, and two 160GB IDE disks with a gigabit Ethernet link.</p><p>They tasted grep and sort workloads with 10^{10} 100-byte records (around 1TB). The results are shown in the terms of data throughput with the timeline.</p><h2 id=main-finding-of-the-paper>MAIN FINDING OF THE PAPER<a hidden class=anchor aria-hidden=true href=#main-finding-of-the-paper>#</a></h2><p>It is useful to abstract a common pattern of certain computing tasks, and create an infrastructure to handle the common issues.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://z1ggy-o.github.io/tags/distributed-systems/>Distributed-Systems</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://z1ggy-o.github.io/>Gy's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>