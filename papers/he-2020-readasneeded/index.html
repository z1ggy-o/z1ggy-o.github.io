<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>FAST'20 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine | Gy's Blog</title>
<meta name=keywords content><meta name=description content="Short Summary
This paper proposed a NAND-flash SSD-friendly full text engine. This engine can
achieve better performance than existing engines with much less memory requested.
They reduce the unnecessary I/O (both the number of I/O and the volume). The
engine does not cache data into memory, instead, read data every time when query
arrive.
They also tried to increase the request size to exploit SSD internal parallelism.
What Is the Problem
Search engines pose great challenges to storage systems:"><meta name=author content="map[link:https://github.com/z1ggy-o name:gyzhu]"><link rel=canonical href=https://z1ggy-o.github.io/papers/he-2020-readasneeded/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://z1ggy-o.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://z1ggy-o.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://z1ggy-o.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://z1ggy-o.github.io/apple-touch-icon.png><link rel=mask-icon href=https://z1ggy-o.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://z1ggy-o.github.io/papers/he-2020-readasneeded/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><meta property="og:url" content="https://z1ggy-o.github.io/papers/he-2020-readasneeded/"><meta property="og:site_name" content="Gy's Blog"><meta property="og:title" content="FAST'20 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine"><meta property="og:description" content="Short Summary This paper proposed a NAND-flash SSD-friendly full text engine. This engine can achieve better performance than existing engines with much less memory requested.
They reduce the unnecessary I/O (both the number of I/O and the volume). The engine does not cache data into memory, instead, read data every time when query arrive.
They also tried to increase the request size to exploit SSD internal parallelism.
What Is the Problem Search engines pose great challenges to storage systems:"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="papers"><meta property="article:published_time" content="2020-12-26T20:15:00+09:00"><meta property="article:modified_time" content="2024-12-28T14:09:27+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="FAST'20 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine"><meta name=twitter:description content="Short Summary
This paper proposed a NAND-flash SSD-friendly full text engine. This engine can
achieve better performance than existing engines with much less memory requested.
They reduce the unnecessary I/O (both the number of I/O and the volume). The
engine does not cache data into memory, instead, read data every time when query
arrive.
They also tried to increase the request size to exploit SSD internal parallelism.
What Is the Problem
Search engines pose great challenges to storage systems:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Papers","item":"https://z1ggy-o.github.io/papers/"},{"@type":"ListItem","position":2,"name":"FAST'20 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine","item":"https://z1ggy-o.github.io/papers/he-2020-readasneeded/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"FAST'20 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine","name":"FAST\u002720 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine","description":"Short Summary This paper proposed a NAND-flash SSD-friendly full text engine. This engine can achieve better performance than existing engines with much less memory requested.\nThey reduce the unnecessary I/O (both the number of I/O and the volume). The engine does not cache data into memory, instead, read data every time when query arrive.\nThey also tried to increase the request size to exploit SSD internal parallelism.\nWhat Is the Problem Search engines pose great challenges to storage systems:\n","keywords":[null],"articleBody":"Short Summary This paper proposed a NAND-flash SSD-friendly full text engine. This engine can achieve better performance than existing engines with much less memory requested.\nThey reduce the unnecessary I/O (both the number of I/O and the volume). The engine does not cache data into memory, instead, read data every time when query arrive.\nThey also tried to increase the request size to exploit SSD internal parallelism.\nWhat Is the Problem Search engines pose great challenges to storage systems:\nlow latency high data throughput high scalability The datasets become too large to fit into the RAM. Simply use RAM as a cache cannot achieve the goal.\nSSD and NVRAM can boost performance well. For example, flash-based SSDs provide much higher throughput and lower latency compared to HDD. However, since SSDs exhibit vastly different characteristic from HDDs, we need to evolve the software on top of the storage stack to exploit the full potential of SSDs.\nIn this paper, the authors rebuild a search engine to better utilize SSDs to achieve the necessary performance goals with main memory that is significantly smaller than the data set.\nWhy the Problem Is Interesting There are already many studies that work on making SSD-friendly softwares within storage stack. For example, RocksDB, Wisckey (KV-store); FlashGraph, Mosaic (graphs processing); and SFS, F2fS (file system).\nHowever, there is no optimization for full-text search engines. Also the challenge of making SSD-friendly search engine is different with other categories of SSD-friendly softwares.\nThe Idea The key idea is: read as needed.\nThe reason behind of the idea is SSD can provide millisecond-level read latency, which is fast enough to avoid cache data into main memory.\nThere are three challenges:\nreduce read amplification hide I/O latency issue large requests to exploit SSD performance (This work is focus on the data structure, inverted index. This is a commonly used data structure in the information retrieve system. There are some brief introduction about the inverted index in the paper, and I do not repeat the content here.)\nCategory Techniques Reduce read amplification - cross-stage data grouping - two-way cost-aware bloom filters - trade disk space for I/O Hide I/O latency adaptive prefetching Issue large requests cross-stage data grouping Cross-stage data grouping This technique is used to reduce read amplification and issue large requests.\nWiSER puts data needed for different stages of a query into continuous and compact blocks on the storage device, which increases block utilization when transferring data for query. Inverted index of WiSER places data of different stages in the order that it will be accessed.\nPrevious search engines used to store data of different stages into different range, which reduces the I/O size and increases the number of I/O requests.\nTwo-way Cost-aware Filters When doing phrase queries we need to use the position information to check the terms around a specific term to improve search precision.\nThe naive approach is to read the positions from all the terms in the phrase then iterate the position list. To reduce the unnecessary reading, WiSER employs a bitmap-based bloom filter. The reason to use bitmap is to reduce the size of bloom filter. There are many empty entries in the filter array, use bitmap can avoid the waste.\nCost-aware means comparing the size of position list with that of the bloom filters. If the size of position list is smaller than that of bloom filters, WiSER reads the position list directly.\nTwo-way filters shares the same idea. WiSER chooses to read the smaller bloom filter to reduce the read amplification.\nAdaptive Prefetching Prefetching is one of the commonly used technique to hide the I/O latency. Even though, the read latency of SSD is small. Compare to DRAM, the read latency of SSD still much larger.\nPrevious search engines (e.g. Elasticsearch) use fix-sized prefecthing (i.e. Linux readahead) which increases the read amplification. WiSER defines an area called prefetch zone. A prefetch zone is further divided into prefetch segments to avoid accessing too much data at a time. It prefetches when all prefetch zones involved in a query are larger than a threshold.\nTo enable adaptive prefetch, WiSER hides the size of the prefetch zone in the highest 16 bits of the offset in TermMap and calls madvise() with the MADV_SEQUENTIAL hint to readahead in the prefetch zone.\nTrade Disk Space for I/O Engines like Elasticsearch put documents into a buffer and compresses all data in the buffer together. WiSER, instead, compresses each document by themselves.\nCompressing all data in the buffer together achieves better compression. However, decompressing a document requires reading and decompressing all documents compressed before the document, leading to more I/O and computation. WiSER trades space for less I/O by using more space but reducing the I/O while processing queries.\nIn the evaluation, WiSER uses 25% more storage than Elasticsearch. The authors argue that the trade-off is acceptable in spite of the low RAM requirement of WiSER.\n","wordCount":"816","inLanguage":"en","datePublished":"2020-12-26T20:15:00+09:00","dateModified":"2024-12-28T14:09:27+08:00","author":{"@type":"Person","name":{"link":"https://github.com/z1ggy-o","name":"gyzhu"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://z1ggy-o.github.io/papers/he-2020-readasneeded/"},"publisher":{"@type":"Organization","name":"Gy's Blog","logo":{"@type":"ImageObject","url":"https://z1ggy-o.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://z1ggy-o.github.io/ accesskey=h title="Gy's Blog (Alt + H)">Gy's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://z1ggy-o.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://z1ggy-o.github.io/weekly/ title=Logs><span>Logs</span></a></li><li><a href=https://z1ggy-o.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://z1ggy-o.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://z1ggy-o.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://z1ggy-o.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://z1ggy-o.github.io/papers/>Papers</a></div><h1 class="post-title entry-hint-parent">FAST'20 - Read as Needed: Building WiSER, a Flash-Optimized Search Engine</h1><div class=post-meta><span title='2020-12-26 20:15:00 +0900 +0900'>December 26, 2020</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;map[link:https://github.com/z1ggy-o name:gyzhu]</div></header><div class=post-content><h2 id=short-summary>Short Summary<a hidden class=anchor aria-hidden=true href=#short-summary>#</a></h2><p>This paper proposed a NAND-flash SSD-friendly full text engine. This engine can
achieve better performance than existing engines with much less memory requested.</p><p>They reduce the unnecessary I/O (both the number of I/O and the volume). The
engine does not cache data into memory, instead, read data every time when query
arrive.</p><p>They also tried to increase the request size to exploit SSD internal parallelism.</p><h2 id=what-is-the-problem>What Is the Problem<a hidden class=anchor aria-hidden=true href=#what-is-the-problem>#</a></h2><p>Search engines pose great challenges to storage systems:</p><ul><li>low latency</li><li>high data throughput</li><li>high scalability</li></ul><p>The datasets become too large to fit into the RAM. Simply use RAM as a cache
cannot achieve the goal.</p><p>SSD and NVRAM can boost performance well. For example, flash-based SSDs provide
much higher throughput and lower latency compared to HDD.
However, since SSDs exhibit vastly different characteristic from HDDs, we need
to evolve the software on top of the storage stack to exploit the full potential
of SSDs.</p><p>In this paper, the authors rebuild a search engine to better utilize SSDs to
achieve the necessary performance goals with main memory that is significantly
smaller than the data set.</p><h2 id=why-the-problem-is-interesting>Why the Problem Is Interesting<a hidden class=anchor aria-hidden=true href=#why-the-problem-is-interesting>#</a></h2><p>There are already many studies that work on making SSD-friendly softwares within storage stack. For example, RocksDB, Wisckey (KV-store); FlashGraph, Mosaic (graphs processing); and SFS, F2fS (file system).</p><p>However, there is no optimization for full-text search engines.
Also the challenge of making SSD-friendly search engine is different with other categories of SSD-friendly softwares.</p><h2 id=the-idea>The Idea<a hidden class=anchor aria-hidden=true href=#the-idea>#</a></h2><p>The key idea is: <strong>read as needed</strong>.</p><p>The reason behind of the idea is SSD can provide millisecond-level read latency,
which is fast enough to avoid cache data into main memory.</p><p>There are three challenges:</p><ol><li>reduce read amplification</li><li>hide I/O latency</li><li>issue large requests to exploit SSD performance</li></ol><p>(This work is focus on the data structure, inverted index. This is a commonly used data structure in the information retrieve system. There are some brief introduction about the inverted index in the paper, and I do not repeat the content here.)</p><table><thead><tr><th>Category</th><th>Techniques</th></tr></thead><tbody><tr><td>Reduce read amplification</td><td>- cross-stage data grouping</td></tr><tr><td></td><td>- two-way cost-aware bloom filters</td></tr><tr><td></td><td>- trade disk space for I/O</td></tr><tr><td>Hide I/O latency</td><td>adaptive prefetching</td></tr><tr><td>Issue large requests</td><td>cross-stage data grouping</td></tr></tbody></table><h3 id=cross-stage-data-grouping>Cross-stage data grouping<a hidden class=anchor aria-hidden=true href=#cross-stage-data-grouping>#</a></h3><p>This technique is used to reduce read amplification and issue large requests.</p><p>WiSER puts data needed for different stages of a query into continuous and compact blocks on the storage device, which increases block utilization when transferring data for query.
Inverted index of WiSER places data of different stages in the order that it will be accessed.</p><p>Previous search engines used to store data of different stages into different range, which reduces the I/O size and increases the number of I/O requests.</p><h3 id=two-way-cost-aware-filters>Two-way Cost-aware Filters<a hidden class=anchor aria-hidden=true href=#two-way-cost-aware-filters>#</a></h3><p>When doing phrase queries we need to use the position information to check the terms around a specific term to improve search precision.</p><p>The naive approach is to read the positions from all the terms in the phrase
then iterate the position list.
To reduce the unnecessary reading, WiSER employs a bitmap-based bloom filter.
The reason to use bitmap is to reduce the size of bloom filter. There are many
empty entries in the filter array, use bitmap can avoid the waste.</p><p><em>Cost-aware</em> means comparing the size of position list with that of the bloom
filters. If the size of position list is smaller than that of bloom filters,
WiSER reads the position list directly.</p><p>Two-way filters shares the same idea. WiSER chooses to read the smaller bloom
filter to reduce the read amplification.</p><h3 id=adaptive-prefetching>Adaptive Prefetching<a hidden class=anchor aria-hidden=true href=#adaptive-prefetching>#</a></h3><p>Prefetching is one of the commonly used technique to hide the I/O latency.
Even though, the read latency of SSD is small. Compare to DRAM, the read latency
of SSD still much larger.</p><p>Previous search engines (e.g. Elasticsearch) use fix-sized prefecthing (i.e.
Linux readahead) which increases the read amplification.
WiSER defines an area called <em>prefetch zone</em>. A prefetch zone is further divided
into prefetch segments to avoid accessing too much data at a time. It prefetches when all prefetch zones involved in a query are larger than a threshold.</p><p>To enable adaptive prefetch, WiSER hides the size of the prefetch zone in the highest 16 bits of the offset in TermMap and calls <code>madvise()</code> with the <code>MADV_SEQUENTIAL</code> hint to readahead in the prefetch zone.</p><h3 id=trade-disk-space-for-i-o>Trade Disk Space for I/O<a hidden class=anchor aria-hidden=true href=#trade-disk-space-for-i-o>#</a></h3><p>Engines like Elasticsearch put documents into a buffer and compresses all data in the buffer together. WiSER, instead, compresses each document by themselves.</p><p>Compressing all data in the buffer together achieves better compression.
However, decompressing a document requires reading and decompressing all documents compressed before the document, leading to more I/O and computation. WiSER trades space for less I/O by using more space but reducing the I/O while processing queries.</p><p>In the evaluation, WiSER uses 25% more storage than Elasticsearch. The authors argue that the trade-off is acceptable in spite of the low RAM requirement of WiSER.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://z1ggy-o.github.io/>Gy's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>